{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 대규모 데이터(big data)의 경우에는 메모리 등의 문제로 특정한 모형은 사용할 수 없는 경우가 많다. 이 때는\n",
    "\n",
    "+ 사전 확률분포를 설정할 수 있는 생성 모형\n",
    "+ 시작 가중치를 설정할 수 있는 모형\n",
    "\n",
    "등을 이용하고 전체 데이터를 처리 가능한 작은 조각으로 나누어 학습을 시키는 점진적 학습 방법을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "path = \"/Library/Fonts/NanumGothic.otf\"\n",
    "font_name = fm.FontProperties(fname=path, size=20).get_name()\n",
    "\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((435759, 54), (145253, 54))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "covtype = fetch_covtype()\n",
    "X_covtype = covtype.data\n",
    "y_covtype = covtype.target - 1  # 1, 2, 3, 4, 5, 6, 7 -> 0, 1, 2, 3, 4, 5, 6\n",
    "classes = np.unique(y_covtype)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_covtype, y_covtype)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "def read_Xy(start, end):\n",
    "    # 실무에서는 파일이나 데이터베이스에서 읽어온다.\n",
    "    idx = list(range(start, min(len(y_train)-1, end)))\n",
    "    X = X_train[idx, :]\n",
    "    y = y_train[idx]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "\n",
    "퍼셉트론 모형은 가중치를 계속 업데이트하므로 \n",
    "#### 일부 데이터를 사용하여 구한 가중치를 다음 단계에서 초기 가중치로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 train acc=0.694 test acc=0.693\n",
      "epoch=1 train acc=0.706 test acc=0.705\n",
      "epoch=2 train acc=0.710 test acc=0.709\n",
      "epoch=3 train acc=0.710 test acc=0.708\n",
      "epoch=4 train acc=0.711 test acc=0.710\n",
      "epoch=5 train acc=0.711 test acc=0.710\n",
      "epoch=6 train acc=0.712 test acc=0.711\n",
      "epoch=7 train acc=0.712 test acc=0.711\n",
      "epoch=8 train acc=0.712 test acc=0.711\n",
      "epoch=9 train acc=0.712 test acc=0.711\n",
      "CPU times: user 6.24 s, sys: 266 ms, total: 6.5 s\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = SGDClassifier(random_state=0)\n",
    "n_split = 10\n",
    "n_X = len(y_test) // n_split # // 나눈 후 정수값만 반환\n",
    "n_epoch = 10\n",
    "\n",
    "for epoch in range(n_epoch): # 데이터를 10개로 나눠서 10번 적용\n",
    "    for n in range(n_split):\n",
    "        X, y = read_Xy(n * n_X, (n+1) * n_X) # 불러들일 데이터의 범위를 설정\n",
    "        model.partial_fit(X, y, classes=classes)\n",
    "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(\"epoch={:d} train acc={:5.3f} test acc={:5.3f}\".format(epoch, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개로 분리하여 각 데이터의 조각들에 대한 정확도를 구한 결과이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브베이즈 모형\n",
    "#### 나이브베이즈 모형과 같은 생성모형은 일부 데이터를 이용하여 구한 확률분포를 사전확률분포로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0 train accuracy=0.631 test accuracy=0.630\n",
      "n=1 train accuracy=0.634 test accuracy=0.633\n",
      "n=2 train accuracy=0.633 test accuracy=0.632\n",
      "n=3 train accuracy=0.633 test accuracy=0.633\n",
      "n=4 train accuracy=0.633 test accuracy=0.632\n",
      "n=5 train accuracy=0.633 test accuracy=0.632\n",
      "n=6 train accuracy=0.632 test accuracy=0.631\n",
      "n=7 train accuracy=0.633 test accuracy=0.632\n",
      "n=8 train accuracy=0.632 test accuracy=0.632\n",
      "n=9 train accuracy=0.632 test accuracy=0.631\n",
      "CPU times: user 7.17 s, sys: 1.51 s, total: 8.67 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = BernoulliNB(alpha=0.1)\n",
    "\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "for n in range(n_split):\n",
    "    X, y = read_Xy(n * n_X, (n+1) * n_X)\n",
    "    model.partial_fit(X, y, classes=classes)\n",
    "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(\"n={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레디언트 부스팅\n",
    "\n",
    "#### 그레디언트 부스팅에서는 초기 커미티 멤버로 일부 데이터를 사용하여 학습한 모형을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0 train accuracy=0.771 test accuracy=0.769\n",
      "n=1 train accuracy=0.794 test accuracy=0.791\n",
      "n=2 train accuracy=0.812 test accuracy=0.808\n",
      "n=3 train accuracy=0.825 test accuracy=0.820\n",
      "n=4 train accuracy=0.833 test accuracy=0.827\n",
      "n=5 train accuracy=0.842 test accuracy=0.836\n",
      "n=6 train accuracy=0.848 test accuracy=0.841\n",
      "n=7 train accuracy=0.853 test accuracy=0.845\n",
      "n=8 train accuracy=0.854 test accuracy=0.846\n",
      "n=9 train accuracy=0.854 test accuracy=0.845\n",
      "CPU times: user 4min 30s, sys: 2.61 s, total: 4min 32s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from lightgbm import train, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(classes),\n",
    "    'learning_rate': 0.2,\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "num_tree = 10\n",
    "model = None\n",
    "for n in range(n_split):\n",
    "    X, y = read_Xy(n*n_X, (n+1)*n_X)\n",
    "    model = train(params, init_model=model, train_set=Dataset(X, y), keep_training_booster=False, num_boost_round=num_tree)\n",
    "    accuracy_train = accuracy_score(y_train, np.argmax(model.predict(X_train), axis=1))\n",
    "    accuracy_test = accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1))\n",
    "    print(\"n={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "랜덤 포레스트와 같은 앙상블 모형에서는 일부 데이터를 사용한 모형을 개별 분류기로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 train accuracy=0.866 test accuracy=0.851\n",
      "epoch=1 train accuracy=0.890 test accuracy=0.870\n",
      "epoch=2 train accuracy=0.898 test accuracy=0.877\n",
      "epoch=3 train accuracy=0.903 test accuracy=0.882\n",
      "epoch=4 train accuracy=0.905 test accuracy=0.884\n",
      "epoch=5 train accuracy=0.906 test accuracy=0.885\n",
      "epoch=6 train accuracy=0.906 test accuracy=0.885\n",
      "epoch=7 train accuracy=0.906 test accuracy=0.885\n",
      "epoch=8 train accuracy=0.907 test accuracy=0.886\n",
      "epoch=9 train accuracy=0.908 test accuracy=0.887\n",
      "CPU times: user 2min 44s, sys: 6.56 s, total: 2min 51s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_split = 10\n",
    "n_X = len(y_train) // n_split\n",
    "num_tree_ini = 10\n",
    "num_tree_step = 10\n",
    "model = RandomForestClassifier(n_estimators=num_tree_ini, warm_start=True)\n",
    "for n in range(n_split):\n",
    "    X, y = read_Xy(n*n_X, (n+1)*n_X)\n",
    "    model.fit(X, y)\n",
    "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
    "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(\"epoch={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))\n",
    "    \n",
    "    model.n_estimators += num_tree_step  # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 정확도가 높게 나타난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
